{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='https://radiant-assets.s3-us-west-2.amazonaws.com/PrimaryRadiantMLHubLogo.png' alt='Radiant MLHub Logo' width='300'/>\n",
    "\n",
    "# Radiant Earth Spot the Crop Challenge\n",
    "# A Guide to Access the data on Radiant MLHub [Downloading individual bands' archives]\n",
    "\n",
    "\n",
    "This notebook walks you through the steps to get access to Radiant MLHub and access the data for the `Radiant Earth Spot the Crop Challenge`. In this updated notebook, you will learn how to download specific bands of Sentinel-2 data instead of the whole archive that might be too large to access. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Radiant MLHub API\n",
    "\n",
    "\n",
    "The Radiant MLHub API gives access to open Earth imagery training data for machine learning applications. You can learn more about the repository at the [Radiant MLHub site](https://mlhub.earth) and about the organization behind it at the [Radiant Earth Foundation site](https://radiant.earth).\n",
    "\n",
    "Full documentation for the API is available at [https://mlhub.earth/docs](https://mlhub.earth/docs).\n",
    "\n",
    "Each item in our collection is explained in json format compliant with [STAC](https://stacspec.org/) [label extension](https://github.com/stac-extensions/label) definition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencies\n",
    "\n",
    "This notebook utilizes the [`radiant-mlhub` Python client](https://pypi.org/project/radiant-mlhub/) for interacting with the API. This notebook also utilizes the [`pandas` library](https://pandas.pydata.org/). If you are running this notebooks using Binder, then these dependencies have already been installed. If you are running this notebook locally, you will need to install these yourself.\n",
    "\n",
    "See the official [`radiant-mlhub` docs](https://radiant-mlhub.readthedocs.io/) for more documentation of the full functionality of that library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name '_download' from 'radiant_mlhub.client' (/Users/michelleroby/radiant-earth/mlhub-tutorials/SouthAfricaCrops/lib/python3.10/site-packages/radiant_mlhub/client/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpathlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Path\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mradiant_mlhub\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mclient\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _download \u001b[38;5;28;01mas\u001b[39;00m download_file\n\u001b[1;32m      9\u001b[0m os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMLHUB_API_KEY\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124md5fe86bf9abf5fef7e1513923b66ee5016768bc55775ccd1abf25c9326e1c8ec\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;66;03m#'N/A'\u001b[39;00m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name '_download' from 'radiant_mlhub.client' (/Users/michelleroby/radiant-earth/mlhub-tutorials/SouthAfricaCrops/lib/python3.10/site-packages/radiant_mlhub/client/__init__.py)"
     ]
    }
   ],
   "source": [
    "# Required libraries\n",
    "import os\n",
    "import tarfile\n",
    "import json\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from radiant_mlhub.client import _download as download_file\n",
    "\n",
    "os.environ['MLHUB_API_KEY'] = 'N/A'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Options\n",
    "\n",
    "By editing the cell below, you can chose which bands of the Sentinel-2 imagery to download and whether or not to download the Sentinel-1 data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DOWNLOAD_S1 = False # If you set this to true then the Sentinel-1 data will be downloaded\n",
    "\n",
    "# Select which imagery bands you'd like to download here\n",
    "DOWNLOAD_BANDS = {\n",
    "    'B01': False,\n",
    "    'B02': False,\n",
    "    'B03': True,\n",
    "    'B04': False,\n",
    "    'B05': False,\n",
    "    'B06': False,\n",
    "    'B07': False,\n",
    "    'B08': False,\n",
    "    'B8A': False,\n",
    "    'B09': False,\n",
    "    'B11': False,\n",
    "    'B12': False,\n",
    "    'CLM': True\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Downloading Datasets and Loading Asset File Paths into a Pandas Dataframe\n",
    "===\n",
    "\n",
    "The cells in this notebook will show you how to download all of the datasets for this competition and read the STAC metadata into a pandas dataframe. There will be two dataframes, one for train and one for test, which contain all of the information you will need to filter based off datetime, satellite platform, and asset type. Contained in each row of the dataframe is also the file path for that asset being described. Assets which have a `None` value for the  `datetime` and `satellite_platform` columns are assets which are related to the label item."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FOLDER_BASE = 'ref_south_africa_crops_competition_v1'\n",
    "\n",
    "def download_archive(archive_name):\n",
    "    if os.path.exists(archive_name.replace('.tar.gz', '')):\n",
    "        return\n",
    "    \n",
    "    print(f'Downloading {archive_name} ...')\n",
    "    download_url = f'https://radiant-mlhub.s3.us-west-2.amazonaws.com/archives/{archive_name}'\n",
    "    download_file(download_url, '.')\n",
    "    print(f'Extracting {archive_name} ...')\n",
    "    with tarfile.open(archive_name) as tfile:\n",
    "        tfile.extractall()\n",
    "    os.remove(archive_name)\n",
    "\n",
    "for split in ['train', 'test']:\n",
    "    # Download the labels\n",
    "    labels_archive = f'{FOLDER_BASE}_{split}_labels.tar.gz'\n",
    "    download_archive(labels_archive)\n",
    "    \n",
    "    # Download Sentinel-1 data\n",
    "    if DOWNLOAD_S1:\n",
    "        s1_archive = f'{FOLDER_BASE}_{split}_source_s1.tar.gz'\n",
    "        download_archive(s1_archive)\n",
    "        \n",
    "\n",
    "    for band, download in DOWNLOAD_BANDS.items():\n",
    "        if not download:\n",
    "            continue\n",
    "        s2_archive = f'{FOLDER_BASE}_{split}_source_s2_{band}.tar.gz'\n",
    "        download_archive(s2_archive)\n",
    "        \n",
    "def resolve_path(base, path):\n",
    "    return Path(os.path.join(base, path)).resolve()\n",
    "        \n",
    "def load_df(collection_id):\n",
    "    split = collection_id.split('_')[-2]\n",
    "    collection = json.load(open(f'{collection_id}/collection.json', 'r'))\n",
    "    rows = []\n",
    "    item_links = []\n",
    "    for link in collection['links']:\n",
    "        if link['rel'] != 'item':\n",
    "            continue\n",
    "        item_links.append(link['href'])\n",
    "        \n",
    "    for item_link in item_links:\n",
    "        item_path = f'{collection_id}/{item_link}'\n",
    "        current_path = os.path.dirname(item_path)\n",
    "        item = json.load(open(item_path, 'r'))\n",
    "        tile_id = item['id'].split('_')[-1]\n",
    "        for asset_key, asset in item['assets'].items():\n",
    "            rows.append([\n",
    "                tile_id,\n",
    "                None,\n",
    "                None,\n",
    "                asset_key,\n",
    "                str(resolve_path(current_path, asset['href']))\n",
    "            ])\n",
    "            \n",
    "        for link in item['links']:\n",
    "            if link['rel'] != 'source':\n",
    "                continue\n",
    "            source_item_id = link['href'].split('/')[-2]\n",
    "            \n",
    "            if source_item_id.find('_s1_') > 0 and not DOWNLOAD_S1:\n",
    "                continue\n",
    "            elif source_item_id.find('_s1_') > 0:\n",
    "                for band in ['VV', 'VH']:\n",
    "                    asset_path = Path(f'{FOLDER_BASE}_{split}_source_s1/{source_item_id}/{band}.tif').resolve()\n",
    "                    date = '-'.join(source_item_id.split('_')[10:13])\n",
    "                    \n",
    "                    rows.append([\n",
    "                        tile_id,\n",
    "                        f'{date}T00:00:00Z',\n",
    "                        's1',\n",
    "                        band,\n",
    "                        asset_path\n",
    "                    ])\n",
    "                \n",
    "            if source_item_id.find('_s2_') > 0:\n",
    "                for band, download in DOWNLOAD_BANDS.items():\n",
    "                    if not download:\n",
    "                        continue\n",
    "                    \n",
    "                    asset_path = Path(f'{FOLDER_BASE}_{split}_source_s2_{band}/{source_item_id}_{band}.tif').resolve()\n",
    "                    date = '-'.join(source_item_id.split('_')[10:13])\n",
    "                    rows.append([\n",
    "                        tile_id,\n",
    "                        f'{date}T00:00:00Z',\n",
    "                        's2',\n",
    "                        band,\n",
    "                        asset_path\n",
    "                    ])\n",
    "            \n",
    "    return pd.DataFrame(rows, columns=['tile_id', 'datetime', 'satellite_platform', 'asset', 'file_path'])\n",
    "\n",
    "train_df = load_df(f'{FOLDER_BASE}_train_labels')\n",
    "test_df = load_df(f'{FOLDER_BASE}_test_labels')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter on Asset Types\n",
    "===\n",
    "This cell will select rows in the test dataframe which are the field_id rasters for the labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.loc[test_df['asset'] == 'field_ids']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter on Satellite Platform\n",
    "===\n",
    "This cell will select only assets which are related to the Sentinel-1 Source Imagery."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.loc[test_df['satellite_platform'] == 's1']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter on Datetime\n",
    "===\n",
    "This cell will select only assets which fall between the specified datetime range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.loc[(test_df['datetime'] >= '2017-04-01T00:00:00+0000') & (test_df['datetime'] < '2017-05-01T00:00:00+0000')]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
