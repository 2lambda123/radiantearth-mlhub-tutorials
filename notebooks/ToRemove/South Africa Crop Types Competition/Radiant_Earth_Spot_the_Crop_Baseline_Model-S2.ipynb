{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a2ae7b9-4da2-472b-860d-5acb063242b0",
   "metadata": {},
   "source": [
    "<img src='https://radiant-assets.s3-us-west-2.amazonaws.com/PrimaryRadiantMLHubLogo.png' alt='Radiant MLHub Logo' width='300'/>\n",
    "\n",
    "# A Baseline Model for the Radiant Earth Spot the Crop Challenge [Sentinel-2 version]\n",
    "\n",
    "This notebook walks you through the steps to load the data and build a baseline model based on Sentinel-2 daya using Random Forests for `Radiant Earth Spot the Crop Challenge`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5894a1e0-23f6-4f8d-940b-1317fba1e762",
   "metadata": {},
   "source": [
    "## Radiant MLHub API\n",
    "\n",
    "\n",
    "The Radiant MLHub API gives access to open Earth imagery training data for machine learning applications. You can learn more about the repository at the [Radiant MLHub site](https://mlhub.earth) and about the organization behind it at the [Radiant Earth Foundation site](https://radiant.earth).\n",
    "\n",
    "Full documentation for the API is available at [https://mlhub.earth/docs](https://mlhub.earth/docs).\n",
    "\n",
    "Each item in our collection is explained in json format compliant with [STAC](https://stacspec.org/) [label extension](https://github.com/stac-extensions/label) definition."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "973f1d8d-12cd-4661-9cf5-c50ecb9b2ab6",
   "metadata": {},
   "source": [
    "## Dependencies\n",
    "\n",
    "All the dependencies for this notebook are included in the `requirements.txt` file included in this folder.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "210d52cd-d81e-446b-8a87-2b0a6cac3bae",
   "metadata": {},
   "source": [
    "**You must replace the `YOUR_API_KEY_HERE` text with your API key which you can obtain by creating a free account on the [MLHub Dashboard](https://mlhub.earth/profile/) within the `API Keys` tab at the top of the page.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a5ec7942-db89-4039-9065-555c6a5775aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required libraries\n",
    "import os\n",
    "import tarfile\n",
    "import json\n",
    "from pathlib import Path\n",
    "from radiant_mlhub.client.resumable_downloader import ResumableDownloader\n",
    "\n",
    "import datetime\n",
    "import rasterio\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "os.environ['MLHUB_API_KEY'] = 'd5fe86bf9abf5fef7e1513923b66ee5016768bc55775ccd1abf25c9326e1c8ec'#'N/A'\n",
    "HOME = os.path.join(os.path.expanduser(\"~\"))\n",
    "output_directory = os.path.join(HOME,'data', 'South-Africa-Crop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9db2d0bd-1658-4d47-ae01-b2f71808303f",
   "metadata": {},
   "outputs": [],
   "source": [
    "DOWNLOAD_S1 = False # If you set this to true then the Sentinel-1 data will be downloaded which is not needed in this notebook.\n",
    "\n",
    "# Select which imagery bands you'd like to download here:\n",
    "DOWNLOAD_BANDS = {\n",
    "    'B01': False,\n",
    "    'B02': False,\n",
    "    'B03': True,\n",
    "    'B04': True,\n",
    "    'B05': False,\n",
    "    'B06': False,\n",
    "    'B07': False,\n",
    "    'B08': True,\n",
    "    'B8A': False,\n",
    "    'B09': False,\n",
    "    'B11': False,\n",
    "    'B12': False,\n",
    "    'CLM': True\n",
    "}\n",
    "\n",
    "# In this model we will only use Green, Red and NIR bands. You can select to download any number of bands. \n",
    "# Our choice relies on the fact that vegetation is most sensitive to these bands. \n",
    "# We also donwload the CLM or Cloud Mask layer to exclude cloudy data from the training phase. \n",
    "# You can also do a feature selection, and try different combination of bands to see which ones will result in a better accuracy. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae21a662-b755-4456-b722-d242c154143c",
   "metadata": {},
   "source": [
    "## Downloading and Loading the Data\n",
    "\n",
    "In this part, we will download the data from Radiant MLHub and load the properties of each item in the dataset into a DataFrame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c9520096",
   "metadata": {},
   "outputs": [],
   "source": [
    "FOLDER_BASE = 'ref_south_africa_crops_competition_v1'\n",
    "\n",
    "def download_archive(archive_name):\n",
    "    if os.path.exists(archive_name.replace('.tar.gz', '')):\n",
    "        return\n",
    "    \n",
    "    print(f'Downloading {archive_name} ...')\n",
    "    download_url = f'https://radiant-mlhub.s3.us-west-2.amazonaws.com/archives/{archive_name}'\n",
    "    out_file = os.path.join(HOME,'data', 'South-Africa-Crop', f'{archive_name}.tar.gz')\n",
    "    dl=ResumableDownloader(url=download_url, out_file='.')\n",
    "    dl.run()\n",
    "    print(f'Extracting {archive_name} ...')\n",
    "    with tarfile.open(archive_name) as tfile:\n",
    "        tfile.extractall()\n",
    "    print(\"here\")\n",
    "    os.remove(archive_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5c452498",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading ref_south_africa_crops_competition_v1_train_labels.tar.gz ...\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'parent'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m split \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;66;03m# Download the labels\u001b[39;00m\n\u001b[1;32m      3\u001b[0m     labels_archive \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mFOLDER_BASE\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msplit\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_labels.tar.gz\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 4\u001b[0m     \u001b[43mdownload_archive\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels_archive\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;66;03m# Download Sentinel-1 data\u001b[39;00m\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m DOWNLOAD_S1:\n",
      "Cell \u001b[0;32mIn[7], line 11\u001b[0m, in \u001b[0;36mdownload_archive\u001b[0;34m(archive_name)\u001b[0m\n\u001b[1;32m      9\u001b[0m out_file \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(HOME,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSouth-Africa-Crop\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00marchive_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.tar.gz\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     10\u001b[0m dl\u001b[38;5;241m=\u001b[39mResumableDownloader(url\u001b[38;5;241m=\u001b[39mdownload_url, out_file\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 11\u001b[0m \u001b[43mdl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExtracting \u001b[39m\u001b[38;5;132;01m{\u001b[39;00marchive_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m ...\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tarfile\u001b[38;5;241m.\u001b[39mopen(archive_name) \u001b[38;5;28;01mas\u001b[39;00m tfile:\n",
      "File \u001b[0;32m~/radiant-earth/mlhub-tutorials/SouthAfricaCrops/lib/python3.10/site-packages/radiant_mlhub/client/resumable_downloader.py:78\u001b[0m, in \u001b[0;36mResumableDownloader.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 78\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mout_file\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparent\u001b[49m\u001b[38;5;241m.\u001b[39mmkdir(exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, parents\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     79\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mout_file\u001b[38;5;241m.\u001b[39mexists():\n\u001b[1;32m     80\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mif_exists \u001b[38;5;241m==\u001b[39m DownloadIfExistsOpts\u001b[38;5;241m.\u001b[39mskip:\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'parent'"
     ]
    }
   ],
   "source": [
    "for split in ['train', 'test']:\n",
    "    # Download the labels\n",
    "    labels_archive = f'{FOLDER_BASE}_{split}_labels.tar.gz'\n",
    "    download_archive(labels_archive)\n",
    "    \n",
    "    # Download Sentinel-1 data\n",
    "    if DOWNLOAD_S1:\n",
    "        s1_archive = f'{FOLDER_BASE}_{split}_source_s1.tar.gz'\n",
    "        download_archive(s1_archive)\n",
    "        \n",
    "\n",
    "    for band, download in DOWNLOAD_BANDS.items():\n",
    "        if not download:\n",
    "            continue\n",
    "        s2_archive = f'{FOLDER_BASE}_{split}_source_s2_{band}.tar.gz'\n",
    "        download_archive(s2_archive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "67e40eac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ref_south_africa_crops_competition_v1_train_labels.tar.gz\n",
      "Downloading ref_south_africa_crops_competition_v1_train_labels.tar.gz ...\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'parent'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m labels_archive \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mFOLDER_BASE\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msplit\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_labels.tar.gz\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(labels_archive)\n\u001b[0;32m----> 5\u001b[0m \u001b[43mdownload_archive\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels_archive\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Download Sentinel-1 data\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m DOWNLOAD_S1:\n",
      "Cell \u001b[0;32mIn[7], line 11\u001b[0m, in \u001b[0;36mdownload_archive\u001b[0;34m(archive_name)\u001b[0m\n\u001b[1;32m      9\u001b[0m out_file \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(HOME,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSouth-Africa-Crop\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00marchive_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.tar.gz\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     10\u001b[0m dl\u001b[38;5;241m=\u001b[39mResumableDownloader(url\u001b[38;5;241m=\u001b[39mdownload_url, out_file\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 11\u001b[0m \u001b[43mdl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExtracting \u001b[39m\u001b[38;5;132;01m{\u001b[39;00marchive_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m ...\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tarfile\u001b[38;5;241m.\u001b[39mopen(archive_name) \u001b[38;5;28;01mas\u001b[39;00m tfile:\n",
      "File \u001b[0;32m~/radiant-earth/mlhub-tutorials/SouthAfricaCrops/lib/python3.10/site-packages/radiant_mlhub/client/resumable_downloader.py:78\u001b[0m, in \u001b[0;36mResumableDownloader.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 78\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mout_file\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparent\u001b[49m\u001b[38;5;241m.\u001b[39mmkdir(exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, parents\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     79\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mout_file\u001b[38;5;241m.\u001b[39mexists():\n\u001b[1;32m     80\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mif_exists \u001b[38;5;241m==\u001b[39m DownloadIfExistsOpts\u001b[38;5;241m.\u001b[39mskip:\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'parent'"
     ]
    }
   ],
   "source": [
    "for split in ['train', 'test']:\n",
    "    # Download the labels\n",
    "    labels_archive = f'{FOLDER_BASE}_{split}_labels.tar.gz'\n",
    "    print(labels_archive)\n",
    "    download_archive(labels_archive)\n",
    "    \n",
    "    # Download Sentinel-1 data\n",
    "    if DOWNLOAD_S1:\n",
    "        s1_archive = f'{FOLDER_BASE}_{split}_source_s1.tar.gz'\n",
    "        download_archive(s1_archive)\n",
    "        \n",
    "\n",
    "    for band, download in DOWNLOAD_BANDS.items():\n",
    "        if not download:\n",
    "            continue\n",
    "        s2_archive = f'{FOLDER_BASE}_{split}_source_s2_{band}.tar.gz'\n",
    "        download_archive(s2_archive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f0134f6-eca7-4daa-8118-482720cbe319",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resolve_path(base, path):\n",
    "    return Path(os.path.join(base, path)).resolve()\n",
    "        \n",
    "def load_df(collection_id):\n",
    "    split = collection_id.split('_')[-2]\n",
    "    collection = json.load(open(f'{collection_id}/collection.json', 'r'))\n",
    "    rows = []\n",
    "    item_links = []\n",
    "    for link in collection['links']:\n",
    "        if link['rel'] != 'item':\n",
    "            continue\n",
    "        item_links.append(link['href'])\n",
    "        \n",
    "    for item_link in item_links:\n",
    "        item_path = f'{collection_id}/{item_link}'\n",
    "        current_path = os.path.dirname(item_path)\n",
    "        item = json.load(open(item_path, 'r'))\n",
    "        tile_id = item['id'].split('_')[-1]\n",
    "        for asset_key, asset in item['assets'].items():\n",
    "            rows.append([\n",
    "                tile_id,\n",
    "                None,\n",
    "                None,\n",
    "                asset_key,\n",
    "                str(resolve_path(current_path, asset['href']))\n",
    "            ])\n",
    "            \n",
    "        for link in item['links']:\n",
    "            if link['rel'] != 'source':\n",
    "                continue\n",
    "            source_item_id = link['href'].split('/')[-2]\n",
    "            \n",
    "            if source_item_id.find('_s1_') > 0 and not DOWNLOAD_S1:\n",
    "                continue\n",
    "            elif source_item_id.find('_s1_') > 0:\n",
    "                for band in ['VV', 'VH']:\n",
    "                    asset_path = Path(f'{FOLDER_BASE}_{split}_source_s1/{source_item_id}/{band}.tif').resolve()\n",
    "                    date = '-'.join(source_item_id.split('_')[10:13])\n",
    "                    \n",
    "                    rows.append([\n",
    "                        tile_id,\n",
    "                        f'{date}T00:00:00Z',\n",
    "                        's1',\n",
    "                        band,\n",
    "                        asset_path\n",
    "                    ])\n",
    "                \n",
    "            if source_item_id.find('_s2_') > 0:\n",
    "                for band, download in DOWNLOAD_BANDS.items():\n",
    "                    if not download:\n",
    "                        continue\n",
    "                    \n",
    "                    asset_path = Path(f'{FOLDER_BASE}_{split}_source_s2_{band}/{source_item_id}_{band}.tif').resolve()\n",
    "                    date = '-'.join(source_item_id.split('_')[10:13])\n",
    "                    rows.append([\n",
    "                        tile_id,\n",
    "                        f'{date}T00:00:00Z',\n",
    "                        's2',\n",
    "                        band,\n",
    "                        asset_path\n",
    "                    ])\n",
    "            \n",
    "    return pd.DataFrame(rows, columns=['tile_id', 'datetime', 'satellite_platform', 'asset', 'file_path'])\n",
    "\n",
    "competition_train_df = load_df(f'{FOLDER_BASE}_train_labels')\n",
    "competition_test_df = load_df(f'{FOLDER_BASE}_test_labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "772258c7-c5a0-4e8c-bf37-98cbb4d88dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "competition_train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bd68551-758a-482f-b022-f6ce59bc27e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This DataFrame lists all types of assets including documentation of the data. \n",
    "# In the following, we will use the Sentinel-2 bands as well as labels. \n",
    "competition_train_df['asset'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdddc229-eb18-424e-8bce-0b1a0ac7cbc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tile_ids_train = competition_train_df['tile_id'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a223bbd2-7b7f-4191-b04d-866297706413",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For simplicty of this baseline model, we will use only 5 images throughout the growing season\n",
    "# You can choose to use all of them, select a few of them at specifc intervals, or \n",
    "# load as many as you want and interpolate between them to have a regular temporal frequency.\n",
    "\n",
    "# Another assumption is that we are selecting the first 5 cloud free images. Ideally, you should\n",
    "# select the images across the different tiles with the same temporal frequency. \n",
    "n_obs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba16fdd-0d81-4661-aab9-e95d6156f329",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our goal is developing a pixel-based Random Forest model. So we will create an X variable\n",
    "# that each row is a pixel and each column is one of the observations. \n",
    "# The other variables is y which has rows equal to the number of pixels. \n",
    "X = np.empty((0, 3 * n_obs))\n",
    "y = np.empty((0, 1))\n",
    "field_ids = np.empty((0, 1))\n",
    "\n",
    "for tile_id in tile_ids_train:\n",
    "    tile_df = competition_train_df[competition_train_df['tile_id']==tile_id]\n",
    "\n",
    "    label_src = rasterio.open(tile_df[tile_df['asset']=='labels']['file_path'].values[0])\n",
    "    label_array = label_src.read(1)\n",
    "    y = np.append(y, label_array.flatten())\n",
    "\n",
    "    field_id_src = rasterio.open(tile_df[tile_df['asset']=='field_ids']['file_path'].values[0])\n",
    "    field_id_array = field_id_src.read(1)\n",
    "    field_ids = np.append(field_ids, field_id_array.flatten())\n",
    "\n",
    "    tile_date_times = tile_df[tile_df['satellite_platform']=='s2']['datetime'].unique()\n",
    "\n",
    "    X_tile = np.empty((256 * 256, 0))\n",
    "    n_X = 0\n",
    "    for date_time in tile_date_times:\n",
    "        # Here we retrieve the cloud band, and check if it's cloud free we will load the other bands\n",
    "        # Otherwise we will pass on to the next observation\n",
    "        \n",
    "        clm_src = rasterio.open(tile_df[(tile_df['datetime']==date_time) & (tile_df['asset']=='CLM')]['file_path'].values[0])\n",
    "        clm_max = np.max(clm_src.read(1))\n",
    "        # In the following we select images that the maximum cloud cover probability per pixel is 10% (10% * 255 = 25.5).\n",
    "        if clm_max < 25:\n",
    "            n_X+=1\n",
    "            b3_src = rasterio.open(tile_df[(tile_df['datetime']==date_time) & (tile_df['asset']=='B03')]['file_path'].values[0])\n",
    "            b3_array = np.expand_dims(b3_src.read(1).flatten(), axis=1)\n",
    "\n",
    "            b4_src = rasterio.open(tile_df[(tile_df['datetime']==date_time) & (tile_df['asset']=='B04')]['file_path'].values[0])\n",
    "            b4_array = np.expand_dims(b4_src.read(1).flatten(), axis=1)\n",
    "\n",
    "            b8_src = rasterio.open(tile_df[(tile_df['datetime']==date_time) & (tile_df['asset']=='B08')]['file_path'].values[0])\n",
    "            b8_array = np.expand_dims(b8_src.read(1).flatten(), axis=1)\n",
    "\n",
    "\n",
    "            X_tile = np.append(X_tile, b3_array, axis = 1)\n",
    "            X_tile = np.append(X_tile, b4_array, axis = 1)\n",
    "            X_tile = np.append(X_tile, b8_array, axis = 1)\n",
    "        if n_X == n_obs:\n",
    "            break\n",
    "        \n",
    "    X = np.append(X, X_tile, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b2543fe-4450-4515-bdab-160e7d206069",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(X)\n",
    "data['label'] = y.astype(int)\n",
    "data['field_id'] = field_ids\n",
    "data = data[data.label != 0] #this filters the pixels that don't have a label (or corresponding field ID)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b72aeb93-f95c-4e40-9f73-ef55982da982",
   "metadata": {},
   "source": [
    "## Building the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de694f2-d2c6-4dd0-a9ff-56f566c439ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each field has several pixels in the data. Here our goal is to build a Random Forest (RF) model using the average values\n",
    "# of the pixels within each field. So, we use `groupby` to take the mean for each field_id\n",
    "data_grouped = data.groupby('field_id').mean().reset_index()\n",
    "data_grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6383d15a-5e27-467d-9ea6-2c7af202a8c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split train and test\n",
    "# We use field_ids to split the data to train and test. Note that the test portion for training is different than the test \n",
    "# portion provided as part of the competition. \n",
    "train_per = 0.7\n",
    "\n",
    "n_fields = len(data_grouped['field_id'])\n",
    "np.random.seed(10)\n",
    "train_fields = np.random.choice(data_grouped['field_id'], int(n_fields * train_per), replace=False)\n",
    "test_fields = data_grouped['field_id'][~np.in1d(data_grouped['field_id'], train_fields)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf3dc6ed-d908-43f3-b854-3d273b45d593",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = data_grouped[data_grouped['field_id'].isin(train_fields)], data_grouped[data_grouped['field_id'].isin(test_fields)]\n",
    "X_train = X_train.drop(columns=['label', 'field_id'])\n",
    "X_test = X_test.drop(columns=['label', 'field_id'])\n",
    "y_train, y_test = data_grouped[data_grouped['field_id'].isin(train_fields)]['label'], data_grouped[data_grouped['field_id'].isin(test_fields)]['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eaf48aa-431f-4b05-a978-6e3729c1ef1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We ran a simple hyperparameter tuning for the number of trees, and concluded to use:\n",
    "n_trees = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fced7dae-01e5-4677-9e41-e94790f057e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting the RF model\n",
    "rf = RandomForestClassifier(n_estimators = n_trees, random_state = 0, n_jobs = 3)\n",
    "rf.fit(X_train, y_train.astype(int))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "548b703c-575d-4ecc-99bd-64d6e6ceeba9",
   "metadata": {},
   "source": [
    "## Competition Test Data\n",
    "\n",
    "In this part we will load the competition test data (which does not have labels) and predict the crop class for each field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f67db15-3866-4641-92cf-c44af29b1396",
   "metadata": {},
   "outputs": [],
   "source": [
    "tile_ids_test = competition_test_df['tile_id'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "565e5451-982a-4cda-9de9-4c939203cdd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_competition_test = np.empty((0, 3 * n_obs))\n",
    "field_ids_test = np.empty((0, 1))\n",
    "\n",
    "for tile_id in tile_ids_test:\n",
    "    tile_df = competition_test_df[competition_test_df['tile_id']==tile_id]\n",
    "    \n",
    "    field_id_src = rasterio.open(tile_df[tile_df['asset']=='field_ids']['file_path'].values[0])\n",
    "    field_id_array = field_id_src.read(1)\n",
    "    field_ids_test = np.append(field_ids_test, field_id_array.flatten())\n",
    "    \n",
    "    tile_date_times = tile_df[tile_df['satellite_platform']=='s2']['datetime'].unique()\n",
    "    \n",
    "    X_tile = np.empty((256 * 256, 0))\n",
    "    n_X = 0\n",
    "    for date_time in tile_date_times:\n",
    "        # Here we retrieve the cloud band, and check if it's cloud free we will load the other bands\n",
    "        # Otherwise we will pass on to the next observation\n",
    "        \n",
    "        clm_src = rasterio.open(tile_df[(tile_df['datetime']==date_time) & (tile_df['asset']=='CLM')]['file_path'].values[0])\n",
    "        clm_max = np.max(clm_src.read(1))\n",
    "        \n",
    "        if clm_max < 25:\n",
    "            n_X+=1\n",
    "            b3_src = rasterio.open(tile_df[(tile_df['datetime']==date_time) & (tile_df['asset']=='B03')]['file_path'].values[0])\n",
    "            b3_array = np.expand_dims(b3_src.read(1).flatten(), axis=1)\n",
    "\n",
    "            b4_src = rasterio.open(tile_df[(tile_df['datetime']==date_time) & (tile_df['asset']=='B04')]['file_path'].values[0])\n",
    "            b4_array = np.expand_dims(b4_src.read(1).flatten(), axis=1)\n",
    "\n",
    "            b8_src = rasterio.open(tile_df[(tile_df['datetime']==date_time) & (tile_df['asset']=='B08')]['file_path'].values[0])\n",
    "            b8_array = np.expand_dims(b8_src.read(1).flatten(), axis=1)\n",
    "\n",
    "\n",
    "            X_tile = np.append(X_tile, b3_array, axis = 1)\n",
    "            X_tile = np.append(X_tile, b4_array, axis = 1)\n",
    "            X_tile = np.append(X_tile, b8_array, axis = 1)\n",
    "        if n_X == n_obs:\n",
    "            break\n",
    "        \n",
    "    X_competition_test = np.append(X_competition_test, X_tile, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a3f26cd-a299-44aa-99b3-7ae562d7564d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = pd.DataFrame(X_competition_test)\n",
    "data_test['field_id'] = field_ids_test\n",
    "data_test = data_test[data_test.field_id != 0]\n",
    "data_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "497b27c4-b08a-43ba-b526-b23edea6bc39",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test_grouped = data_test.groupby('field_id').mean().reset_index()\n",
    "data_test_grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97ded63f-3f5e-497b-a10a-05882d466bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_competition_prob = rf.predict_proba(data_test_grouped.drop(columns=['field_id']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf3be09-3bbd-440d-bce8-94a665e60602",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this part we format the DataFrame to have column names and order similar to the sample submission file. \n",
    "pred_df = pd.DataFrame(y_competition_prob)\n",
    "pred_df = pred_df.rename(columns={\n",
    "    0:'Crop_ID_1',\n",
    "    1:'Crop_ID_2', \n",
    "    2:'Crop_ID_3',\n",
    "    3:'Crop_ID_4',\n",
    "    4:'Crop_ID_5',\n",
    "    5:'Crop_ID_6',\n",
    "    6:'Crop_ID_7',\n",
    "    7:'Crop_ID_8',\n",
    "    8:'Crop_ID_9'\n",
    "})\n",
    "pred_df['field_id']=data_test_grouped['field_id']\n",
    "pred_df = pred_df[['field_id', 'Crop_ID_1', 'Crop_ID_2', 'Crop_ID_3', 'Crop_ID_4', 'Crop_ID_5', 'Crop_ID_6', 'Crop_ID_7', 'Crop_ID_8', 'Crop_ID_9']]\n",
    "pred_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4541f43b-520a-4f12-b797-3b64630a6527",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the predicted probabilites to a csv for submission\n",
    "pred_df.to_csv('baseline_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0deeeab-d5e9-499f-a026-0b6c73f8a04e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
