{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='https://radiant-assets.s3-us-west-2.amazonaws.com/PrimaryRadiantMLHubLogo.png' alt='Radiant MLHub Logo' width='300'/>\n",
    "\n",
    "# How to use the Radiant MLHub API to browse and download a sample dataset\n",
    "\n",
    "\n",
    "\n",
    "This Jupyter notebook, which you may copy and adapt for any use, utilizes the [`radiant-mlhub` Python client](https://pypi.org/project/radiant-mlhub/) to show examples of how to download labels and source imagery for the NASA Flood Extent Detection dataset. \n",
    "\n",
    "We'll show you how to set up your authorization, explore the dataset properties, and retrieve the data from Radiant MLHub.\n",
    "\n",
    "Radiant MLHub uses [STAC](https://stacspec.org/) standard for cataloging training datasets. Each item in our collections are explained in json format compliant with STAC [label extension](https://github.com/radiantearth/stac-spec/tree/master/extensions/label) definition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Authentication\n",
    "\n",
    "### Create an API Key\n",
    "\n",
    "Access to the Radiant MLHub API requires an API key. To get your API key, go to [mlhub.earth](https://mlhub.earth/). If you have not used Radiant MLHub before, you will need to sign up and create a new account. Otherwise, sign in. In the **API Keys** tab, you'll be able to create API key(s), which you will need. *Do not share* your API key with others: your usage may be limited and sharing your API key is a security risk.\n",
    "\n",
    "### Configure the Client\n",
    "\n",
    "Once you have your API key, you need to configure the `radiant_mlhub` library to use that key. There are a number of ways to configure this (see the [Authentication docs](https://radiant-mlhub.readthedocs.io/en/latest/authentication.html) for details). \n",
    "\n",
    "For these examples, we will set the `MLHUB_API_KEY` environment variable. Replace 'YOUR API KEY' with your API key and run the cell below to save your API key as an environment variable that the client library will recognize.\n",
    "\n",
    "*If you are running this notebook locally and have configured a profile as described in the [Authentication docs](https://radiant-mlhub.readthedocs.io/en/latest/authentication.html), then you do not need to execute this cell.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from radiant_mlhub import Dataset, Collection\n",
    "from dateutil.parser import parse\n",
    "\n",
    "os.environ['MLHUB_API_KEY'] = 'YOUR API KEY'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of all Datasets\n",
    "datasets = Dataset.list()\n",
    "for dataset in datasets:\n",
    "    print(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Listing Dataset Properties\n",
    "\n",
    "The following cell makes a request to the API for the properties for the NASA Flood Extent Detection Dataset and prints out a few important properties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset.fetch('nasa_floods_v1')\n",
    "\n",
    "print(f'Title: {dataset.title}')\n",
    "print(f'DOI: {dataset.doi}')\n",
    "print(f'Citation: {dataset.citation}')\n",
    "print('\\nCollection IDs and License:')\n",
    "for collection in dataset.collections:\n",
    "    print(f'    {collection.id} : {collection.license}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloading Assets\n",
    "\n",
    "This next cell will call the dataset download function with a filter specified which only downloads the `raster_label` and `VV` source assets within the `nasa_floods_v1` collection. For more information about filtering downloads, reference the [collection and asset key filtering method in the Python client documenation](https://radiant-mlhub.readthedocs.io/en/latest/datasets.html#filter-by-collection-and-asset-keys).\n",
    "\n",
    "This next section will download a subset of the `nasa_floods_v1` collection. The `Dataset.download()` function is called and utilizes all three of the filter options: spatial filter, temporal filter, and collection filter. For more information about the filtering downloads available through `radiant-mlhub`, reference the [collection and asset key filtering method in the Python client documenation](https://radiant-mlhub.readthedocs.io/en/latest/datasets.html#filter-by-collection-and-asset-keys)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the Area of Interest (aoi) for the spatial filter\n",
    "aoi = {\n",
    "  \"type\": \"Feature\",\n",
    "  \"properties\": {},\n",
    "  \"geometry\": {\n",
    "    \"type\": \"Polygon\",\n",
    "    \"coordinates\": [\n",
    "      [\n",
    "        [\n",
    "          88.79150390625,\n",
    "          22.705255477207526\n",
    "        ],\n",
    "        [\n",
    "          93.49365234375,\n",
    "          22.705255477207526\n",
    "        ],\n",
    "        [\n",
    "          93.49365234375,\n",
    "          27.068909095463365\n",
    "        ],\n",
    "        [\n",
    "          88.79150390625,\n",
    "          27.068909095463365\n",
    "        ],\n",
    "        [\n",
    "          88.79150390625,\n",
    "          22.705255477207526\n",
    "        ]\n",
    "      ]\n",
    "    ]\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the dates for the temporal filter\n",
    "my_start_date=parse(\"2017-06-01T00:00:00+0000\")\n",
    "my_end_date=parse(\"2017-06-30T00:00:00+0000\")\n",
    "\n",
    "# Defining the desired collections for the collection filter\n",
    "asset_filter = dict(\n",
    "    nasa_floods_v1_labels=['raster_label'],\n",
    "    nasa_floods_v1_source=['VV']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.download(intersects=aoi, datetime=(my_start_date, my_end_date), collection_filter=asset_filter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download All Assets\n",
    "\n",
    "If no filters are defined, the `dataset.download` function will download the entire `nasa_floods_v1` dataset to the current working directory. If you would like to explore the entire dataset, run the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.download()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
